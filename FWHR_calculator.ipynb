{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all the code needed to automatically calculate the Facial-Width-Height ratio based on an image using the `face_recognition` package.  \n",
    "**See: https://github.com/ageitgey/face_recognition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'FWHR_calculator'\n",
    "PYTHON_VERSION = '3.5'\n",
    "AUTHOR = 'Ties de Kok'\n",
    "MODIFIED BY = 'Carl Lindersson'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modification ideas - By Carl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Rotate images to better fit the horisontal lines. - Enables more accurate reading of fWHR \n",
    "####    - minimize the hight differens between left and right side. \n",
    "#### 2. Store and orginize data automatically in existing numbers/excell file. - Enables more rapid testing and less human error variation.\n",
    "####    - Investigate the pipeline, note steps of data aquisition \n",
    "####    - Note steps needing to be automated\n",
    "####    - Write psudo code for the general pipeline of the project \n",
    "####    - Write psudo code for each step in particular \n",
    "####    - Write the code following your psudo code. \n",
    "#### 3. Find sutable error check calibrations - Enable more accurate reading of large data and minimise human error variation \n",
    "####    - Test problematic, slightly problematic and good images to find a good cut-off point. \n",
    "3. Script to get fWHR from list of images - DONE \n",
    "4. Print image with box outlined - enabele rapid error check - DONE \n",
    "5. Tweak face points used to better reflect fWHR - Enable more accurate measures - In progress \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Scrape Stats, Names, Image URLs and Images from web\n",
    "\n",
    "#Stats saved in: \n",
    "#Images saved in: \n",
    "\n",
    "import bs4\n",
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import requests\n",
    "import pandas as pd \n",
    "import json \n",
    "from selenium import webdriver\n",
    "import urllib.request\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "def ScrapePlayerInfo(TeamURL):\n",
    "#--------------- Selenium Experiment --------------\n",
    "    #cookies = dict(BCPermissionLevel='PERSONAL')\n",
    "        #driver = webdriver.Chrome(\"/Users/carllindersson/Documents/Neurovetenskap/Programs/chromedriver\")\n",
    "    # Set chrome as head driver in selenium\n",
    "        #driver = webdriver.Firefox()\n",
    "    # set teamURLs as the webbpage that the driver goes to \n",
    "        #driver.get(TeamURL)\n",
    "    # Variable for the webpage (where the driver has navigated)\n",
    "       # html = driver.page_source\n",
    "    # variable for Beautifulsoup parsing the website the driver has navigated to.\n",
    "       # page_soup = soup(html)\n",
    "#--------------------------------------------------   \n",
    "   # Bypass cookie agreement  \n",
    "    from http import cookiejar  \n",
    "    class BlockAll(cookiejar.CookiePolicy):\n",
    "        return_ok = set_ok = domain_return_ok = path_return_ok = lambda self, *args, **kwargs: False\n",
    "        netscape = True\n",
    "        rfc2965 = hide_cookie2 = False\n",
    "    \n",
    "    s = requests.Session()\n",
    "    s.cookies.set_policy(BlockAll())\n",
    "#--------------------------------------------------\n",
    "    \n",
    "    # set Team webpage as source for data collection / scrape \n",
    "    source = s.get(TeamURL).text\n",
    "    # set up BeautifulSoup to parse the source website using the html.parser\n",
    "    page_soup = soup(source, 'html.parser')\n",
    "\n",
    "    # Variables indicating points of interests on the webpage by the page's html tags \n",
    "  \n",
    "    Table = page_soup.find('div', class_=\"ResponsiveTable ResponsiveTable--fixed-left mt5 remove_capitalize\")\n",
    "    Names = Table.find('tbody', class_=\"Table__TBODY\")\n",
    "\n",
    "    Stat_table = Table.find(\"div\", class_=\"Table__Scroller\")\n",
    "    table_row = Stat_table.find('tr', class_='Table__TR Table__TR--sm Table__even')\n",
    "\n",
    "    # Name and statistics lists made from elements with same tag \n",
    "    Name_tag_list = Names.find_all('a', class_='AnchorLink')\n",
    "    Stat_row_tag_list = Stat_table.find_all('tr', class_='Table__TR Table__TR--sm Table__even')\n",
    "\n",
    "    #create empty lists to store data in \n",
    "    Name_list = []\n",
    "    Stat_list = []\n",
    "    Name_Stat_list = []\n",
    "\n",
    "    #looping through the names and stats, adding them to the list Names_Stat_list\n",
    "    for Name, row in zip(Name_tag_list, Stat_row_tag_list):\n",
    "        Name_list.append(str(Name.text).replace('  ',' ')) # list each player's names\n",
    "        Team_name_tag = page_soup.find('div', class_=\"ClubhouseHeader__Main_Aside pl4 relative\").find('h1').text\n",
    "        Name_list.append(Team_name_tag)\n",
    "        for stat in row:\n",
    "            Stat_list.append(str(stat.text)) # lists each inner iteration, the stats for each player \n",
    "        Name_Stat_list.append(Name_list + Stat_list)  # appends the stats for each player as specific elements in a separate list.  \n",
    "        Stat_list = [] # clear Stat_list so that the inner iteration does not contain the previous players stats. \n",
    "        Name_list = [] # clear Name_list so that the outer iteration does not contain the previous players Name or Team.\n",
    "\n",
    "    # Create dataframe from Name_stat_list\n",
    "    df_Name_Stat = pd.DataFrame(Name_Stat_list)\n",
    "    df_Name_Stat.rename(columns = {0: 'Name',1:'Team'}, inplace=True)\n",
    "\n",
    "    #Set column names using list of stat names \n",
    "        #1. Create list of stat headings \n",
    "    Table_headings_list = page_soup.find_all('th', class_=\"tar stats-cell Table__TH\")[0:13]\n",
    "    Heading_name_list = ['Name', 'Team'] # 'Name' was not in the Table heading list and needed to be manually added.\n",
    "    for heading in Table_headings_list:\n",
    "        Heading_name_list.append(heading.text)\n",
    "\n",
    "        #2. Assign list as the column names of the dataframe\n",
    "    df_Name_Stat.columns = Heading_name_list\n",
    "\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    # Loop through list of player bios and extract their weight, height, image url, image and name.\n",
    "\n",
    "    # list with all player profile links \n",
    "    Name_link_list = []\n",
    "    for info in Name_tag_list: \n",
    "        Name_link_list.append(info.get('href'))\n",
    "    \n",
    "    \n",
    "    All_Content_list = []\n",
    "    Content_list = []\n",
    "    for link in Name_link_list:\n",
    "        # Find html tags for picture url, hight, and weight \n",
    "        New_source = requests.get(link).text\n",
    "        page_soup = soup(New_source, 'html.parser')\n",
    "        Content_list = []\n",
    "\n",
    "        if page_soup.find('div', class_=\"main-headshot-65 floatleft\"):\n",
    "            Main_url_tag = page_soup.find('div', class_=\"main-headshot-65 floatleft\")\n",
    "            Url_tag = Main_url_tag.find('img').get('src')\n",
    "            Content_list.append(Url_tag)\n",
    "            Name2_tag = Main_url_tag.find('img').get('alt') # name to later controll of it matches the other dataframe names. \n",
    "            Content_list.append(Name2_tag)\n",
    "            Height_Weight_tag = page_soup.find('ul', class_=\"general-info\").find('li').next_sibling.text.split(',')\n",
    "            Height = Height_Weight_tag[0].replace('\"', '').replace(\"' \", '').replace(\"' \", '')\n",
    "            feet = int(Height[0])\n",
    "            inches = int(Height[1:2])\n",
    "            feet_in_inches = feet * 12\n",
    "            Height_centimeters = (feet_in_inches + inches) * 2.54 # Convert feet and inches to centimeters \n",
    "            Content_list.append(Height_centimeters)\n",
    "            Weight = int(Height_Weight_tag[1].replace('lbs','')) * 0.45359237   # Convert lbs to kg \n",
    "            Content_list.append(Weight)\n",
    "            Position_tag = page_soup.find('ul', class_=\"general-info\").find('li', class_='first').text[-2:]#Player's position \n",
    "            Content_list.append(Position_tag)\n",
    "        elif page_soup.find('div', class_=\"main-headshot\"): # Other layout of page with other tag\n",
    "            Main_url_tag = page_soup.find('div', class_=\"main-headshot\")\n",
    "            Url_tag = Main_url_tag.find('img').get('src')\n",
    "            Content_list.append(Url_tag)\n",
    "            Name2_tag = Main_url_tag.find('img').get('alt') # name to later controll of it matches the other dataframe names. \n",
    "            Content_list.append(Name2_tag)\n",
    "            Height_Weight_tag = page_soup.find('ul', class_=\"general-info\").find('li').next_sibling.text.split(',')\n",
    "            Height = Height_Weight_tag[0].replace('\"', '').replace(\"' \", '').replace(\"' \", '')\n",
    "            feet = int(Height[0])\n",
    "            inches = int(Height[1:2])\n",
    "            feet_in_inches = feet * 12\n",
    "            Height_centimeters = (feet_in_inches + inches) * 2.54\n",
    "            Content_list.append(Height_centimeters)\n",
    "            Weight = int(Height_Weight_tag[1].replace('lbs','')) * 0.45359237   # Convert lbs to kg \n",
    "            Content_list.append(Weight)\n",
    "            Position_tag = page_soup.find('ul', class_=\"general-info\").find('li', class_='first').text[-2:]#Player's position \n",
    "            Content_list.append(Position_tag)\n",
    "        else:\n",
    "            pass\n",
    "        All_Content_list.append(Content_list)\n",
    " \n",
    "    df_profile = pd.DataFrame(All_Content_list) # Create dataframe from list of player bio content.\n",
    "    df_profile.rename(columns = {0: 'Image URL',1: 'Name',2: 'Height(cm)',3: 'Weight(kg)',4: 'Position'}, inplace=True) # Set heading names\n",
    "#------------------------------------------------------\n",
    "        #Downloads images from urls in df.profile  \n",
    "    \n",
    "    df_Image_Download = df_profile[['Name','Image URL']] # creates dataframe only containing name and url \n",
    "    \n",
    "    for i,j in df_Image_Download.itertuples(index=False): # i becomes first column (Name) and j the second (Image URL). Index is ignored.\n",
    "        if not isinstance(i, str)==True: \n",
    "            filename = 'unknown'\n",
    "        else:\n",
    "            filename = i # save jpg as the current player name column \n",
    "        file_path = '/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Photos/test_table_photos/'\n",
    "        full_path = '{}{}'.format(file_path, filename)\n",
    "        if not isinstance(j, str)==True: # if j (the URL column element) is not a string, and hence, not a url, move on.  \n",
    "            continue\n",
    "        else: \n",
    "            urllib.request.urlretrieve(j, full_path) # download file from url string and save it in/as full_path\n",
    "          # print(filename,\"saved.\")\n",
    "#------------------------------------------------------  \n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "    # Combine both Name_stat and Player bio DataFrames while matching the rows using the name columns as indicators\n",
    "    df_complete = df_Name_Stat.join(df_profile.set_index('Name'), on='Name') \n",
    "    #print(df_complete)\n",
    "    \n",
    "    # Append df_complete to a csv that later will contain all teams' statistics\n",
    "    df_complete.to_csv('/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Statistics/All_but_fWHR.csv', mode = 'a', header=False) \n",
    "#-----------------------------------------------------------------------------------------\n",
    "\n",
    "#create csv file to later append fwhr-statistics to. \n",
    "csv_header_list = ['Team Index','Name','Team','GP','G','A','PTS','+/-','PIM','TOI/G','PPG','PPA','SHG','SHA','S','SPCT','Image URL','Height(cm)','Weight(kg)','Position']\n",
    "import csv\n",
    "with open('/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Statistics/All_but_fWHR.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(csv_header_list)\n",
    "    \n",
    "#--------------------------------------------------\n",
    "#Gets fwhr on the images and then add the correct ratio to the correct name in the statistics files. \n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#create list to later append data to \n",
    "fwhr_list = []\n",
    "#list of faces from directory\n",
    "faces_list = [f for f in os.listdir(\"/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Photos/test_table_photos\") if not f.startswith('.')]\n",
    "#loop through list, get fwhr and append with player name to df_fwhr\n",
    "for face in faces:\n",
    "    os.chdir(\"/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Photos/test_table_photos\")\n",
    "    fWHR_Eyebrow = get_fwhr(face, show=False, top='eyebrow')\n",
    "    fWHR_Eyelid = get_fwhr(face, show=False, top='eyelid')\n",
    "    row_list = [str(face),str(fWHR_Eyebrow),str(fWHR_Eyelid)]\n",
    "    fwhr_list.append(row_list)\n",
    "    #df_row = pd.DataFrame(row_list)\n",
    "    #df_fwhr.append(df_row)\n",
    "\n",
    "df_fWHR = pd.DataFrame(fwhr_list, columns=['Name','fWHR Eyebrow', 'fWHR Eyelid'])\n",
    "\n",
    "\n",
    "#df_fwhr = pd.read_csv('playerfwhr.csv', names=[\"Name\",\"fWHR Eyebrow\",\"fWHR Eyelid\"], index_col=False)\n",
    "\n",
    "    \n",
    "#--------------------------------------------------\n",
    "    \n",
    "#list of Team Pages to scrape \n",
    "Team_page_list = ['https://www.espn.com/nhl/team/stats/_/name/tor/season/2008/seasontype/2','https://www.espn.com/nhl/team/stats/_/name/cgy/season/2008/seasontype/2','https://www.espn.com/nhl/team/stats/_/name/edm/season/2008/seasontype/2','https://www.espn.com/nhl/team/stats/_/name/mtl/season/2008/seasontype/2','https://www.espn.com/nhl/team/stats/_/name/ott/season/2008/seasontype/2','https://www.espn.com/nhl/team/stats/_/name/van/season/2008/seasontype/2']\n",
    "\n",
    "# loop that calls the scrape funciton on the team page list. \n",
    "for TeamPage in Team_page_list:\n",
    "    ScrapePlayerInfo(TeamPage)\n",
    "    \n",
    "# Add df_fwhr to the dataframe and turn the final fully appended csv-file to an excel file\n",
    "df_all_but_fwhr = pd.read_csv('/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Statistics/All_but_fWHR.csv')\n",
    "df_final = df_all_but_fwhr.join(df_fWHR.set_index('Name'), on='Name')\n",
    "writer = pd.ExcelWriter('/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Statistics/Complete_Table.xlsx')\n",
    "df_final.to_excel(writer, index = False)\n",
    "writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "#writer2 = pd.csvWriter('/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Statistics/Complete_Table.xlsx')\n",
    "df_final.to_csv('/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Statistics/Complete_Table.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-29e0065c0191>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# download file from url and save it in/as full_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;31m#        print(filename,\"saved.\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m#--------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 543\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1360\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##### Structure and organise data\n",
    "## Step 1 - Get names and images through wget\n",
    "# 1. Select file and header\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import urllib.request\n",
    "df = pd.read_excel('/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Names_and_Image_URLs/test_table.xlsx', header=0)\n",
    "  # show all rows in dataframe\n",
    "pd.set_option('display.max_rows', None)\n",
    "# 2. copy name2 and name3 to and paste to Name1 column / replace empty spaces in Name1 with names from Name2 and 3 (test on name 2 to 3)\n",
    "    #### OBS! The This code ONLY adjust for Name1-3 and Image_URL1-3. If more colums are used, change code. \n",
    "if 'Name2' in df.columns:\n",
    "    df['Name1'] = df['Name1'].fillna(df.Name2)\n",
    "if 'Name3' in df.columns:\n",
    "    df['Name1'] = df['Name1'].fillna(df.Name3)\n",
    "# 3. copy URL2 and URL3 and paste to URL1 column \n",
    "if \"Image_URL2\" in df.columns:\n",
    "    df['Image_URL1'] = df['Image_URL1'].fillna(df.Image_URL2)\n",
    "if \"Image_URL3\" in df.columns:\n",
    "    df['Image_URL1'] = df['Image_URL1'].fillna(df.Image_URL3)  \n",
    "# 4. Create data frame with only Name1 and Image_URL1 \n",
    "df2 = df[[\"Name1\", \"Image_URL1\"]]\n",
    "\n",
    "#-------------------------------------\n",
    "#   Only needed for using wget and possibly later error checks. \n",
    "\n",
    "# 5. Save Name1 and URL1 as \"file_name_pruned\"\n",
    "df2.to_excel('/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Names_and_Image_URLs/test_table_pruned.xlsx')\n",
    "# 6. Remove spaces and special characters (') from colums, saving new data frame as \"df3\" \n",
    "df3 = pd.DataFrame(df2)\n",
    "df3['Name1'] = df2['Name1'].str.replace(' ', '')\n",
    "df3['Name1'] = df2['Name1'].str.replace(\"'\", \"\")\n",
    "df3['Image_URL1'] = df2['Image_URL1'].str.replace(' ', '')\n",
    "df3['Image_URL1'] = df2['Image_URL1'].str.replace(\"'\", \"\")\n",
    "# 7. Move df3 to .txt file, remove headers and index, and save in the folder for names and urls\n",
    "df3.to_string('/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Names_and_Image_URLs/test_table_wget', header=False, index=False)\n",
    "    # also a csv file to see if it is better. \n",
    "df3.to_csv('/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Names_and_Image_URLs/test_table_download', header=False, index=False)\n",
    "#-------------------------------------\n",
    "        #Downloads images from urls in df2 \n",
    "    \n",
    "# 8. run wget on text/cvs-file / or use python code to get images from df2 \n",
    "   \n",
    "    \n",
    "for i,j in df2.itertuples(index=False): # i becomes first column (Name1) and j the second (Imaeg_URL1). Index is ignored.\n",
    "    if not isinstance(i, str)==True: \n",
    "        filename = unknown\n",
    "    else:\n",
    "        filename = i # save jpg as the current player name column \n",
    "    file_path = '/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Photos/test_table_photos/'\n",
    "    full_path = '{}{}'.format(file_path, filename)\n",
    "    if not isinstance(j, str)==True: # if j (the URL column element) is not a string, and hence, not a url, move on.  \n",
    "        continue\n",
    "    else: \n",
    "        urllib.request.urlretrieve(j, full_path) # download file from url and save it in/as full_path\n",
    "#        print(filename,\"saved.\")\n",
    "#--------------------------------------   \n",
    "\n",
    "\n",
    "# 9. save images into specific image folder called \"Sample_Name_Images\" OBS! Make sure it can be found by the fWHR_calculator-code later. \n",
    "\n",
    "## 2. Organise stats, names and images\n",
    "# 1. Combine stat sheet with image/Name data \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### use python code to get images\n",
    "\n",
    "#------------------------------ \n",
    "\n",
    "def URL_to_jpg(i, url, file_path):\n",
    "    \n",
    "    filename = '{}.jpg'.format(urls['Name1'])\n",
    "    full_path = '{}{}'.format(file_path, filename)\n",
    "    urllib.request.urlretrieve(url, full_path)\n",
    "    \n",
    "    print(' {} saved.'.format(filename))\n",
    "    \n",
    "    return None \n",
    "#----------------------------\n",
    "    # constants\n",
    "FILENAME = 'test_table_pruned.xlsx'\n",
    "FILEPATH = '/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Photos/test_table_photos'\n",
    "#----------------------------\n",
    "#read list of urls as panda data frame \n",
    "urls = pd.read_excel(FILENAME)\n",
    "\n",
    "# Save images in chosen directory by iterating through list\n",
    "if i in urls:\n",
    "    for i, url in urls['Image_URL1']:\n",
    "        URL_to_jpg(i, url[1], FILEPATH)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for examples? Click here: [Examples](#examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib import pyplot as plt #####* added by Carl to use plt.show() in the show_box function \n",
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "\n",
    "import urllib.request "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All the heavy-lifting is done by the `face_recognition` package, you need to have it installed!**  \n",
    "**See: https://github.com/ageitgey/face_recognition**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function loads an image from the drive or downloads it from a link if `url` is set to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, url=False):\n",
    "    if not url:\n",
    "        return face_recognition.load_image_file(path)\n",
    "    else:\n",
    "        if path[-3:] == 'jpg' or  path[-3:] == 'peg': #######Change to -4 to jpeg to make it more intuitive\n",
    "            urllib.request.urlretrieve(path, 'tmp.jpg')\n",
    "            return face_recognition.load_image_file('tmp.jpg')\n",
    "        elif path[-3:] == 'png':\n",
    "            urllib.request.urlretrieve(path, 'tmp.png')\n",
    "            return face_recognition.load_image_file('tmp.png')\n",
    "        else:\n",
    "            print(\"Unknown image type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get the contour face points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calculates the coordinates for the corners of the \"FWHR\" box.  \n",
    "*Note 1:* it is possible to calculate the top line based on either the bottom of the eyebrows (`top = \"eyebrow\"`) or the eyelids (`top = \"eyelid\"`).  \n",
    "*Note 2:* to counter-act small amounts of rotation it will by default take the average between the height of the two top points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face_points(points, method='average', top='eyebrow'):\n",
    "    width_left, width_right = points[0], points[16] #####* Chaged by Carl to optimise performance\n",
    "    \n",
    "    if top == 'eyebrow':\n",
    "        top_left = points[21] #####* Chaged by Carl to optimise performance\n",
    "        top_right = points[22] #####* Chaged by Carl to optimise performance\n",
    "        \n",
    "    elif top == 'eyelid':\n",
    "        top_left = points[37]\n",
    "        top_right = points[43] \n",
    "        \n",
    "    else:\n",
    "        raise ValueError('Invalid top point, use either \"eyebrow\" or \"eyelid\"')\n",
    "        \n",
    "    bottom_left, bottom_right = points[50], points[52]\n",
    "    \n",
    "    if method == 'left':\n",
    "        coords = (width_left[0], width_right[0], top_left[1], bottom_left[1])\n",
    "        \n",
    "    elif method == 'right':\n",
    "        coords = (width_left[0], width_right[0], top_right[1], bottom_right[1])\n",
    "        \n",
    "    else:\n",
    "        top_average = int((top_left[1] + top_right[1]) / 2)\n",
    "        bottom_average = int((bottom_left[1] + bottom_right[1]) / 2)\n",
    "        coords = (width_left[0], width_right[0], top_average, bottom_average)\n",
    "        \n",
    "    ## Move the line just a little above the top of the eye to the eyelid    \n",
    "#####*    if top == 'eyelid':\n",
    "#####*        coords = (coords[0], coords[1], coords[2] - 4, coords[3])      \n",
    "    #####* Above Changed by Carl to optimise performance. If noted code above is performed the top==eyelid setting is too high.\n",
    "\n",
    "    return {'top_left' : (coords[0], coords[2]),\n",
    "            'bottom_left' : (coords[0], coords[3]),\n",
    "            'top_right' : (coords[1], coords[2]),\n",
    "            'bottom_right' : (coords[1], coords[3])\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to check suitability of picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function checks whether a picture contains a person that is looking straight at the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_picture_check(p, debug=False):\n",
    "    ## To scale for picture size\n",
    "    width_im = (p[16][0] - p[0][0]) / 100 \n",
    "    \n",
    "    ## Difference in height between eyes\n",
    "    eye_y_l = (p[37][1] + p[41][1]) / 2.0\n",
    "    eye_y_r = (p[44][1] + p[46][1]) / 2.0\n",
    "    eye_dif = (eye_y_r - eye_y_l) / width_im\n",
    "    \n",
    "    ## Difference top / bottom point nose \n",
    "    nose_dif = (p[30][0] - p[27][0]) / width_im\n",
    "    \n",
    "    ## Space between face-edge to eye, left vs. right\n",
    "    left_space = p[36][0] - p[0][0]\n",
    "    right_space = p[16][0] - p[45][0]\n",
    "    space_ratio = left_space / right_space\n",
    "    \n",
    "    if debug:\n",
    "        print(eye_dif, nose_dif, space_ratio)\n",
    "    \n",
    "    ## These rules are not perfect, determined by trying a bunch of \"bad\" pictures\n",
    "    if eye_dif > 5 or nose_dif > 3.5 or space_ratio > 3:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate the FWHR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calculates the FWHR based on the corners: `Width / Height`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FWHR_calc(corners):\n",
    "    width = corners['top_right'][0] - corners['top_left'][0]\n",
    "    height = corners['bottom_left'][1] - corners['top_left'][1]\n",
    "    return float(width) / float(height)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to show the FWHR box on the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function shows the FWHR box on the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_box(image, corners):\n",
    "    pil_image = Image.fromarray(image)\n",
    "    w, h = pil_image.size\n",
    "    \n",
    "    ## Automatically determine width of the line depending on size of picture\n",
    "    line_width = math.ceil(h / 100)\n",
    "    \n",
    "    d = ImageDraw.Draw(pil_image) \n",
    "    d.line([corners['bottom_left'], corners['top_left']], width = line_width)\n",
    "    d.line([corners['bottom_left'], corners['bottom_right']], width = line_width)\n",
    "    d.line([corners['top_left'], corners['top_right']], width = line_width)\n",
    "    d.line([corners['top_right'], corners['bottom_right']], width = line_width)\n",
    "    \n",
    "    #####* Added by Carl - Show line for brow angle\n",
    "   # d.line([points[19], points[21]], width = line_width) #####* Left brow angle \n",
    "   # d.line([points[44], points[42]], width = line_width) #####* Right brow angle \n",
    "    \n",
    "    imshow(pil_image)\n",
    "    plt.show() #####* added by Carl to enable that the image shows for each time the function is called in a loop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final function that combines the previous functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function combines all the previous logic into one function.  \n",
    "\n",
    "Arguments:\n",
    "\n",
    "`image_path` $\\rightarrow$ path or URL to image  \n",
    "`url` $\\rightarrow$ set to `True` if `image_path` is a url  \n",
    "`show` $\\rightarrow$ set to `False` if you only want it to return the FWHR  \n",
    "`method` $\\rightarrow$ determines which eye to use for the top point: `left`, `right`, or `average`  \n",
    "`top` $\\rightarrow$ determines whether to use the `eyebrow` as top point or `eyelid` as top point  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fwhr(image_path, url=False, show=True, method='average', top='eyebrow'):\n",
    "    image = load_image(image_path, url)\n",
    "    landmarks = face_recognition.api._raw_face_landmarks(image)\n",
    "    landmarks_as_tuples = [(p.x, p.y) for p in landmarks[0].parts()]\n",
    "    \n",
    "    if good_picture_check(landmarks_as_tuples): \n",
    "        corners = get_face_points(landmarks_as_tuples, method=method, top = top)\n",
    "        fwh_ratio = FWHR_calc(corners)\n",
    "        \n",
    "        if show:\n",
    "            print('The Facial-Width-Height ratio is: {}'.format(fwh_ratio))\n",
    "            show_box(image, corners)\n",
    "            \n",
    "        else:\n",
    "            return fwh_ratio\n",
    "    else:\n",
    "        if show:\n",
    "            print(\"Picture is not suitable to calculate fwhr.\")\n",
    "            imshow(image)\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "<a id='examples'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure Scraped Data - Automate data aquisition and organisation after scrape. \n",
    "1. Get images from scraped URLs using wget \n",
    "2. Create table of names and stats combined\n",
    "3. Save fWHR measure to the name/stat-list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 1. Get images from scraped URLs \n",
    "\n",
    "# 1. Remove spaces from name/URL-list \n",
    "#    1. Create folder and file where Scraped Names, Image URLs, and Stat data will be saved. \n",
    "#    2. Create two test-files for the two outputs from scrape storm. These will be used to test automation code.\n",
    "#    3. Write code that combines the name columns to one column \n",
    "            # Might need to covert to CVS or text file \n",
    "#    4. Code that combines the image URL columns to one column \n",
    "#    5. Code that remove spaces in the name column\n",
    "#    6. Code that removes special characters such as ' , \" etc... \n",
    "#    7. Code that create text file with names and image URLs, saved in appropriate name/URL folder.\n",
    "# 2. Use wget to download the images from the URLs \n",
    "#    8. Code that use xargs wget to download the images\n",
    "#    9. Create folder for images \n",
    "#    9. Code that moves the images into a sample-specific folder and then to the approprate image folder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 1. Get images from scraped URLs \n",
    "\n",
    "# 1. Remove spaces from name/URL-list \n",
    "#    1. Create folder and file where Scraped Names, Image URLs, and Stat data will be saved. \n",
    "#    2. Create two test-files for the two outputs from scrape storm. These will be used to test automation code.\n",
    "#    3. Write code that combines the name columns to one column \n",
    "            # Might need to covert to CVS or text file \n",
    "import pandas as pd \n",
    "df = pd.read_excel ('/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Names_and_Image_URLs/test_table.xlsx', header=[1]) #select file and header (row 1)   \n",
    "# select the name2 and name3 columns and copy \n",
    "# Paste to name1 column\n",
    "# select URL2 and URL3 columns and copy \n",
    "# Paste to URL1 column\n",
    "# Delete all columns except name1 and URL1 \n",
    "# Save file as \"file_name_pruned \"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displays fWHR box-outline, fWHR and file name of image\n",
    "*program written by carl* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-352-bee4c2f2d5da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_paths\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfull_path_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m    \u001b[0;31m# print(image_paths[103:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mget_fwhr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'average'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eyebrow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-349-f8a6252ecfeb>\u001b[0m in \u001b[0;36mget_fwhr\u001b[0;34m(image_path, url, show, method, top)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_fwhr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'average'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eyebrow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_face_landmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlandmarks_as_tuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlandmarks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_image' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "images_names_list = os.listdir('/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Canada_ESPN_Images/')\n",
    "full_path_list = ['/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Canada_ESPN_Images/' + x for x in images_names_list]\n",
    "for image_paths in full_path_list:\n",
    "   # print(image_paths[103:])\n",
    "    get_fwhr(image_paths, url=False, show=True, method='average', top='eyebrow')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gets fWHR of images\n",
    "**Saves fWHR of Images together with their file names as playerfwhr.txt and playerfwhr.cvc**\n",
    "\n",
    "*written by Oskar and Carl*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-158-e1413cd6b580>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#    outfile.write(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Statistics\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mdf_fwhr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'playerfwhr.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Name\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"fWHR_Eyebrow\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"fWHR_Eyelid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mdf_fwhr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2037\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2038\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_column_name\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os, numpy as np\n",
    "import pandas as pd\n",
    "os.chdir(\"/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Statistics\")\n",
    "with open('playerfwhr.csv', 'w') as finallist:\n",
    "    os.chdir(\"/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Photos/test_table_photos\")\n",
    "    faces = [f for f in os.listdir(\"/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Photos/test_table_photos\") if not f.startswith('.')]\n",
    "    #faces = os.listdir()\n",
    "    for face in faces:\n",
    "        fWHR_Eyebrow = get_fwhr(faces, show=False, top='eyebrow')\n",
    "        \n",
    "  #  fWHR_Eyebrow = [get_fwhr(x, show=False, top='eyebrow') for x in faces]\n",
    "  #  fWHR_Eyelid = [get_fwhr(x, show=False,top='eyelid') for x in faces]\n",
    "  #  results = [faces,fWHR_Eyebrow,fWHR_Eyelid]\n",
    "    #results = np.column_stack((faces,fWHR_Eyebrow,fWHR_Eyelid))\n",
    "    finallist.write(\"%s\\n\" % results)\n",
    "    \n",
    "#os.chdir(\"/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Statistics\")\n",
    "#with open('playerfwhr.txt', 'r') as infile, open('playerfwhr.csv', 'w') as outfile:\n",
    "#    data = infile.read()\n",
    "#    data = data.replace(\"[[\", \"\")\n",
    "#    data = data.replace(\" [\", \"\")\n",
    "#    data = data.replace(\"]\", \"\")\n",
    "#    data = data.replace(\" [0:9]\", \",\")\n",
    "#    data = data.replace(\"'\", \"\")\n",
    "#    outfile.write(data)\n",
    "os.chdir(\"/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Statistics\")\n",
    "df_fwhr = pd.read_csv('playerfwhr.csv', names=[\"Name\",\"fWHR_Eyebrow\",\"fWHR_Eyelid\"], index_col=False)\n",
    "df_fwhr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Aaron Downey', '1.9523809523809523', '2.342857142857143'], ['Aaron Miller', '1.9615384615384615', '2.217391304347826'], ['Adrian Aucoin', '1.68', '1.9534883720930232'], ['Ales Hemsky', '1.803921568627451', '2.090909090909091'], ['Alex Burrows', '1.8444444444444446', '2.1842105263157894'], ['Alex Foster', '1.9318181818181819', '2.361111111111111'], ['Alex Kovalev', '1.7291666666666667', '1.930232558139535'], ['Alex Tanguay', '1.9111111111111112', '2.15'], ['Alexander Edler', '1.816326530612245', '2.022727272727273'], ['Alexander Perezhogin', '1.8181818181818181', '2.0'], ['Alexander Steen', '1.74', '2.0232558139534884'], ['Alexei Ponikarovsky', '2.022222222222222', '2.275'], ['Anders Eriksson', '1.9', '2.375'], ['Andrei Kostitsyn', '1.6226415094339623', '1.8695652173913044'], ['Andrei Markov', '1.875', '2.3076923076923075'], ['Andrew Cogliano', '1.7608695652173914', '2.025'], ['Andy Wozniewski', '1.76', '2.0'], ['Antoine Vermette', '1.8695652173913044', '2.097560975609756'], ['Anton Stralman', '1.8333333333333333', '2.046511627906977'], ['Anton Volchenkov', '1.8679245283018868', '2.357142857142857'], ['Bates Battaglia', '2.0', '2.526315789473684'], ['Ben Ondrus', '1.88', '2.292682926829268'], ['Boyd Devereaux', '1.6538461538461537', '2.0476190476190474'], ['Brad Isbister', '1.92', '2.1818181818181817'], ['Brendan Morrison', '1.6938775510204083', '1.8863636363636365'], ['Brian Pothier', '1.9545454545454546', '2.0476190476190474'], ['Brooks Laich', '1.7954545454545454', '2.0789473684210527'], ['Bryan McCabe', '1.9375', '2.325'], ['Bryan Smolinski', '1.8823529411764706', '2.1333333333333333'], ['Bryan Young', '2.0', '2.2857142857142856'], ['Byron Ritchie', '1.8333333333333333', '2.0952380952380953'], ['Carlo Colaiacovo', '1.9', '2.261904761904762'], ['Chad Kilger', '1.96', '2.3333333333333335'], ['Chris Kelly', 'None', 'None'], ['Chris Neil', '2.1794871794871793', '2.4285714285714284'], ['Chris Phillips', '1.9565217391304348', '2.4324324324324325'], ['Christopher Higgins', '1.653061224489796', '2.025'], ['Cory Sarich', '1.8043478260869565', '2.075'], ['Craig Conroy', '1.9777777777777779', '2.282051282051282'], ['Craig Rivet', '1.7959183673469388', '2.1463414634146343'], ['Curtis Glencross', '1.8297872340425532', '2.2051282051282053'], ['Curtis Leschyshyn', '2.1363636363636362', '2.238095238095238'], ['Daniel Alfredsson', '1.8679245283018868', '1.98'], ['Daniel Sedin', '1.9318181818181819', '2.0238095238095237'], ['Darcy Tucker', '1.8888888888888888', '2.125'], ['Darryl Boyce', '1.7755102040816326', '2.1219512195121952'], ['David Hale', '1.875', '2.25'], ['David Moss', '1.6545454545454545', '1.8958333333333333'], ['Daymond Langkow', '1.830188679245283', '2.1555555555555554'], ['Denis Grebeshkov', '2.08', '2.311111111111111'], ['Denis Hamel', '1.72', '2.15'], ['Dick Tarnstrom', '1.84', '2.090909090909091'], ['Dion Phaneuf', '1.9555555555555555', '2.0952380952380953'], ['Dominic Moore', '1.8837209302325582', '2.076923076923077'], ['Dustin Boyd', '1.8541666666666667', '2.282051282051282'], ['Dustin Penner', '1.8979591836734695', '2.1136363636363638'], ['Eric Godard', '1.8043478260869565', '2.1842105263157894'], ['Eric Nystrom', '1.8888888888888888', '2.125'], ['Ethan Moreau', '1.6666666666666667', '1.9318181818181819'], ['Fernando Pisani', '1.7547169811320755', '1.9787234042553192'], ['Francis Bouillon', '1.9148936170212767', '2.3076923076923075'], ['Garth Murray', '2.0', '2.4705882352941178'], ['Geoff Sanderson', '1.75', '2.0'], ['Greg de Vries', '1.96', '2.3333333333333335'], ['Guillaume Latendresse', '1.851063829787234', '2.3513513513513513'], ['Hal Gill', '1.98', '2.302325581395349'], ['Henrik Sedin', '1.9772727272727273', '2.1219512195121952'], ['Ian White', '2.1904761904761907', '2.4864864864864864'], ['Janne Niinimaa', '1.8', '2.1176470588235294'], ['Jannik Hansen', '1.8085106382978724', '2.073170731707317'], ['Jarome Iginla', '1.8333333333333333', '2.3157894736842106'], ['Jarret Stoll', '1.7272727272727273', '2.111111111111111'], ['Jason Blake', '1.78', '2.225'], ['Jason Jaffray', '1.9130434782608696', '2.2'], ['Jason Spezza', '1.9333333333333333', '2.0232558139534884'], ['Jean-Francois Jacques', '1.7755102040816326', '2.0714285714285716'], ['Jeff Cowan', '2.0', '2.1'], ['Jeremy Williams', '1.7755102040816326', '2.175'], ['Jim Vandermeer', '1.8125', '2.1219512195121952'], ['Jiri Tlusty', '1.7872340425531914', '2.27027027027027'], ['Jody Hull', '1.826086956521739', '2.0'], ['John Pohl', '2.066666666666667', '2.3846153846153846'], ['Joni Pitkanen', '1.7843137254901962', '2.022222222222222'], ['Josh Gorges', '1.7254901960784315', '2.0'], ['Josh Langfeld', '2.0', '2.235294117647059'], ['Karel Rachunek', '1.6666666666666667', '2.0'], ['Kevin Bieksa', '2.0454545454545454', '2.25'], ['Kris Beech', '2.0416666666666665', '2.3333333333333335'], ['Kris Newbury', '1.72', '2.097560975609756'], ['Kristian Huselius', '1.9574468085106382', '2.358974358974359'], ['Kyle Brodziak', '1.9545454545454546', '2.2051282051282053'], ['Kyle Wellwood', '1.690909090909091', '2.1136363636363638'], ['Ladislav Smid', '1.8541666666666667', '2.1707317073170733'], ['Liam Reddox', '1.78', '2.119047619047619'], ['Lukas Krajicek', '1.826086956521739', '2.0'], ['Marc-Antoine Pouliot', '1.8636363636363635', '2.0'], ['Marcus Nilson', '1.6037735849056605', '1.9318181818181819'], ['Marian Hossa', '1.8076923076923077', '2.186046511627907'], ['Mark Bell', '2.025', '2.189189189189189'], ['Mark Smith', '1.8571428571428572', '2.1666666666666665'], ['Mark Streit', '1.8297872340425532', '2.2051282051282053'], ['Markus Naslund', '1.8421052631578947', '2.0588235294117645'], ['Martin Havlat', '1.7826086956521738', '1.9523809523809523'], ['Marty Reasoner', '1.82', '2.2195121951219514'], ['Mason Raymond', '1.8478260869565217', '2.125'], ['Mathieu Dandenault', '1.6956521739130435', '2.1666666666666665'], ['Mathieu Roy', '1.9130434782608696', '2.2'], ['Mats Sundin', '2.0', '2.4'], ['Matt Cooke', '1.9333333333333333', '2.175'], ['Matt Greene', '1.6923076923076923', '2.0'], ['Matt Pettinger', '2.0476190476190474', '2.15'], ['Matt Stajan', '1.7916666666666667', '2.15'], ['Matthew Lombardi', '1.78', '1.9777777777777779'], ['Mattias Ohlund', '1.6923076923076923', '1.9555555555555555'], ['Maxim Lapierre', '2.0217391304347827', '2.4473684210526314'], ['Michael Ryder', '1.7450980392156863', '2.022727272727273'], ['Mike Brown', '1.9130434782608696', '2.3157894736842106'], ['Mike Fisher', '1.8888888888888888', '2.1794871794871793'], ['Mike Johnson', '1.9090909090909092', '2.210526315789474'], ['Mike Komisarek', '1.8846153846153846', '2.130434782608696'], ['Mike Weaver', '1.76', '2.0'], ['Mikhail Grabovski', '1.875', '2.0930232558139537'], ['Nathan McIver', '1.7551020408163265', '1.9545454545454546'], ['Nik Antropov', '1.875', '2.3076923076923075'], ['Owen Nolan', '1.8888888888888888', '2.2666666666666666'], ['Patrick Thoresen', '1.9565217391304348', '2.3684210526315788'], ['Pavel Kubina', '1.7884615384615385', '2.066666666666667'], ['Peter Bondra', '1.894736842105263', '2.1176470588235294'], ['Peter Schaefer', '1.849056603773585', '2.3333333333333335'], ['Petr Schastlivy', '1.9583333333333333', '2.35'], ['Radek Bonk', '1.8421052631578947', '2.3333333333333335'], ['Raffi Torres', '1.8936170212765957', '2.225'], ['Rhett Warrener', '1.8421052631578947', '2.1875'], ['Rick Rypien', '1.82', '2.3947368421052633'], ['Rob Ray', '2.12', '2.5238095238095237'], ['Rob Schremp', '1.851063829787234', '2.0714285714285716'], ['Robbie Earl', '1.7115384615384615', '2.0697674418604652'], ['Robert Nilsson', '1.7222222222222223', '2.066666666666667'], ['Robyn Regehr', '2.119047619047619', '2.282051282051282'], ['Ryan Kesler', '1.7674418604651163', '2.111111111111111'], ['Ryan Shannon', '1.875', '2.3076923076923075'], ['Saku Koivu', '2.0476190476190474', '2.2051282051282053'], ['Sam Gagner', '1.6888888888888889', '2.0'], ['Sami Salo', '1.7346938775510203', '1.9767441860465116'], ['Serge Payer', '1.85', '2.0555555555555554'], ['Sergei Samsonov', '2.0', '2.1951219512195124'], ['Shane Hnidy', '1.7826086956521738', '2.05'], ['Shaun Van Allen', '1.75', '2.210526315789474'], ['Shawn Horcoff', '1.8604651162790697', '2.2222222222222223'], ['Sheldon Souray', '1.934782608695652', '2.0697674418604652'], ['Simon Gamache', '1.894736842105263', '2.25'], ['Staffan Kronwall', '1.9130434782608696', '2.0952380952380953'], ['Stephane Yelle', '1.894736842105263', '2.1176470588235294'], ['Steve Begin', '1.836734693877551', '2.142857142857143'], ['Steve Staios', '1.7142857142857142', '2.1333333333333333'], ['Taylor Pyatt', '1.7555555555555555', '1.9268292682926829'], ['Theo Peckham', '1.86', '2.325'], ['Tim Ramholt', '1.8', '2.142857142857143'], ['Todd Simpson', '2.05', '2.2777777777777777'], ['Todd White', '1.7555555555555555', '1.975'], ['Tom Gilbert', 'None', 'None'], ['Tomas Kaberle', '1.9814814814814814', '2.3260869565217392'], ['Tomas Plekanec', '1.82', '2.1666666666666665'], ['Trevor Linden', '1.84', '2.090909090909091'], ['Vaclav Varada', '1.894736842105263', '2.0'], ['Wade Belak', '1.8333333333333333', '2.0952380952380953'], ['Wade Redden', '1.7234042553191489', '2.025'], ['Wayne Primeau', '1.9361702127659575', '2.3333333333333335'], ['Willie Mitchell', '1.85', '2.0555555555555554'], ['Zack Fitzgerald', '1.9318181818181819', '2.236842105263158'], ['Zack Stortini', '1.7346938775510203', '2.0238095238095237'], ['Zdeno Chara', '1.6956521739130435', '1.813953488372093']]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#create list to later append data to \n",
    "fwhr_list = []\n",
    "#list of faces from directory\n",
    "faces_list = [f for f in os.listdir(\"/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Photos/test_table_photos\") if not f.startswith('.')]\n",
    "#loop through list, get fwhr and append with player name to df_fwhr\n",
    "for face in faces:\n",
    "    os.chdir(\"/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Scraped_Data/Photos/test_table_photos\")\n",
    "    fWHR_Eyebrow = get_fwhr(face, show=False, top='eyebrow')\n",
    "    fWHR_Eyelid = get_fwhr(face, show=False, top='eyelid')\n",
    "    row_list = [str(face),str(fWHR_Eyebrow),str(fWHR_Eyelid)]\n",
    "    fwhr_list.append(row_list)\n",
    "    #df_row = pd.DataFrame(row_list)\n",
    "    #df_fwhr.append(df_row)\n",
    "\n",
    "df_fWHR = pd.DataFrame(fwhr_list, columns=['Name','fWHR Eyebrow', 'fWHR Eyelid'])\n",
    "print(fwhr_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference `eyelid` vs. `eyebrow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama_url =  'https://www.biography.com/.image/ar_1:1%2Cc_fill%2Ccs_srgb%2Cg_face%2Cq_auto:good%2Cw_300/MTE4MDAzNDEwNzg5ODI4MTEw/barack-obama-12782369-1-402.jpg'\n",
    "get_fwhr(obama_url, url=True, top = 'eyelid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_fwhr(obama_url, url=True, top = 'eyebrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FWHR only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_fwhr(obama_url, url=True, top = 'eyebrow', show=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection of bad picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_img_url_1 = 'http://s-media-cache-ak0.pinimg.com/originals/0d/02/d2/0d02d28791fab2a6f056648dc174033c.jpg'\n",
    "get_fwhr(bad_img_url_1, url=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_img_url_2 = '/Users/carllindersson/Documents/Neurovetenskap/fWHR_Summer/Behaviour_and_statistics/Canada_NHL_images'\n",
    "get_fwhr(bad_img_url_2, url=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data points used in the functions above use this picture as reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as ImageShow\n",
    "ImageShow(url = 'https://cdn-images-1.medium.com/max/1600/1*AbEg31EgkbXSQehuNJBlWg.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
